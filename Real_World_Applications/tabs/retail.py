# -*- coding: utf-8 -*-
"""Retail.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1mzQLKePnCkxCro9pVR2Cy_fyrENznj3l
"""
import streamlit as st
from streamlit_option_menu import option_menu
import pandas as pd
import numpy as np
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.metrics.pairwise import cosine_similarity
import datetime
import os
import requests
from io import BytesIO
from PIL import Image, ImageDraw
#import mediapipe as mp
import cv2
from streamlit_webrtc import webrtc_streamer, VideoTransformerBase
import av

def render_styled_table(df):
    st.markdown("""
        <style>
            .styled-table {
                border-collapse: collapse;
                margin: 25px 0;
                font-size: 0.9em;
                font-family: 'Segoe UI', Tahoma, Geneva, Verdana, sans-serif;
                width: 100%;
                border: 1px solid #ddd;
            }
            .styled-table th, .styled-table td {
                padding: 12px 15px;
                border: 1px solid #ddd;
                text-align: center;
            }
            .styled-table thead {
                background-color: #009879;
                color: #ffffff;
            }
            .styled-table tbody tr:nth-child(even) {
                background-color: #f3f3f3;
            }
        </style>
    """, unsafe_allow_html=True)

    html_table = df.to_html(index=False, classes="styled-table")
    st.markdown(html_table, unsafe_allow_html=True)

class RetailTab:

    def __init__(self):
        pass

    def Personalized_Product_Recommendations(self):
        st.markdown("---", unsafe_allow_html=True)
        st.markdown(
        """
        <div style='
            background-color: #EEEEEE;
            padding: 10px 20px;
            border-radius: 10px;
            border: 1px solid #ccc;
            margin-bottom: 30px;
            text-align: center;
        '>
            <h4 style='color: #1a1a1a;'> Simulate a product recommendation engine based on user interactions and product similarities </h4>
        """,
        unsafe_allow_html=True
                )

        # --- Simulated Product Catalog ---
        def get_image_url(category):
            category_map = {
                "Footwear": "shoes",
                "Fitness": "fitness",
                "Electronics": "technology",
                "Wearables": "wearable",
                "Health": "health",
                "Accessories": "accessory",
                "Outdoor": "outdoor",
                "Home": "home",
                "Furniture": "furniture"
            }
            tag = category_map.get(category, "product")
            return f"https://loremflickr.com/200/200/{tag}?lock={np.random.randint(1,1000)}"

        def load_product_catalog():
            data = {
                "ProductID": [f"P{i:03d}" for i in range(1, 21)],
                "ProductName": [
                    "Running Shoes", "Bluetooth Speaker", "Yoga Mat", "Noise Cancelling Headphones",
                    "Wireless Mouse", "Smart Watch", "Protein Powder", "Laptop Stand", "Hiking Backpack",
                    "Electric Toothbrush", "Water Bottle", "Desk Lamp", "Gaming Chair", "Treadmill Mat",
                    "Fitness Tracker", "Portable Charger", "Jump Rope", "Resistance Bands", "Smart Scale",
                    "Action Camera"
                ],
                "Category": [
                    "Footwear", "Electronics", "Fitness", "Electronics", "Electronics", "Wearables", "Health",
                    "Accessories", "Outdoor", "Health", "Fitness", "Home", "Furniture", "Fitness",
                    "Wearables", "Electronics", "Fitness", "Fitness", "Health", "Electronics"
                ],
                "Tags": [
                    "shoes running sport", "audio speaker bluetooth", "yoga fitness mat",
                    "headphones noise bluetooth", "mouse wireless pc", "watch smart fitness",
                    "protein supplement health", "laptop ergonomic stand", "hiking outdoor travel",
                    "toothbrush electric oral", "bottle water gym", "lamp desk light",
                    "gaming chair comfort", "mat treadmill fitness", "fitness tracker wearable",
                    "charger portable power", "jump rope cardio", "bands resistance workout",
                    "scale smart health", "camera action sport"
                ],
                "Price": np.random.randint(20, 200, 20),
                "Rating": np.round(np.random.uniform(3.0, 5.0, 20), 1),
                  "ReviewCount": np.random.randint(20, 500, 20)
                }
            df = pd.DataFrame(data)
            df["BuyURL"] = df["ProductID"].apply(lambda pid: f"https://example.com/buy/{pid}")
            df["ImageURL"] = df["Category"].apply(get_image_url)
            return df

        products_df = load_product_catalog()

        # --- Simulated User Interaction History ---
        user_profiles = {
            "Allan Smith": ["P001", "P017", "P003"],  # Fitness enthusiast
            "Joseph Curling": ["P002", "P004", "P005"],  # Electronics lover
            "Sharon Wilkins": ["P009", "P010", "P019"]   # Outdoor & health
        }

        selected_user = st.selectbox("Select User", list(user_profiles.keys()))

        # --- Filter Options ---
        st.markdown(" ", unsafe_allow_html=True)
        st.markdown(" ", unsafe_allow_html=True)
        st.markdown(
        """
        <div style='
            background-color: #EEEEEE;
            padding: 10px 20px;
            border-radius: 10px;
            border: 1px solid #ccc;
            margin-bottom: 30px;
            text-align: center;
        '>
            <h4 style='color: #1a1a1a;'> üîé Filter Recommendations </h4>
        """,
        unsafe_allow_html=True
                )
        #st.header("üîé Filter Recommendations")
        price_range = st.sidebar.slider("Price Range ($)", 20, 200, (30, 150))
        category_filter = st.sidebar.multiselect(
            "Product Categories", options=products_df["Category"].unique().tolist(), default=[])

        st.write("Previously Interacted Products:")
        st.table(products_df[products_df["ProductID"].isin(user_profiles[selected_user])][["ProductName", "Category", "Price"]])

        # --- Recommender Logic (Content-Based using Tags) ---
        vectorizer = TfidfVectorizer()
        tfidf_matrix = vectorizer.fit_transform(products_df['Tags'])
        sim_matrix = cosine_similarity(tfidf_matrix)

        # Get indices of interacted products
        interacted_indices = products_df[products_df["ProductID"].isin(user_profiles[selected_user])].index.tolist()
        sim_scores = np.mean(sim_matrix[interacted_indices], axis=0)

        # Top N Recommendations (excluding already seen)
        top_indices = sim_scores.argsort()[::-1]
        recommended = []
        for idx in top_indices:
            product = products_df.loc[idx]
            if product["ProductID"] not in user_profiles[selected_user]:
                if category_filter and product["Category"] not in category_filter:
                    continue
                if not (price_range[0] <= product["Price"] <= price_range[1]):
                    continue
                tag_overlap = set(product['Tags'].split()) & set(
                    ' '.join(products_df.loc[interacted_indices]['Tags'].tolist()).split())
                recommended.append((product, sim_scores[idx], ', '.join(tag_overlap)))
            if len(recommended) >= 6:
                break

        # --- Display Recommendations ---
        st.subheader("‚ú® You may also like:")
        clicked_items = []
        cols = st.columns(3)
        for i, rec in enumerate(recommended):
            product, score, overlap = rec
            with cols[i % 3]:
                st.image(product['ImageURL'], width=150)
                st.markdown(f"**{product['ProductName']}**")
                st.write(f"Category: {product['Category']}")
                st.write(f"Price: ${product['Price']}")
                st.write(f"‚≠ê {product['Rating']} ({product['ReviewCount']} reviews)")
                st.caption(f"Similarity: {score:.2f} | Tags matched: {overlap}")
                if st.button(f"üõí Buy Now ({product['ProductID']})", key=f"buy_{product['ProductID']}"):
                    timestamp = datetime.datetime.now().strftime("%Y-%m-%d %H:%M:%S")
                    clicked_items.append(product['ProductID'])
                    st.success(f"üõçÔ∏è Redirecting to checkout for {product['ProductName']}...")
                    st.markdown(f"[Click here to complete purchase]({product['BuyURL']})", unsafe_allow_html=True)
                    log_entry = pd.DataFrame([[selected_user, product['ProductID'], timestamp]],
                                            columns=["UserID", "ProductID", "Timestamp"])
                    log_path = "click_log.csv"
                    if os.path.exists(log_path):
                        log_entry.to_csv(log_path, mode='a', header=False, index=False)
                    else:
                        log_entry.to_csv(log_path, index=False)

        if clicked_items:
           st.info(f"üìù Click Log Updated: {', '.join(clicked_items)}")

        # Then show your next component:
        selected_module = st.radio(
            "Select Finance Module",
            ["üö® Credit Card Fraud Detection", "üè¶ Loan Approval Prediction"]
        )

    def Dynamic_Pricing(self):
        st.markdown("---", unsafe_allow_html=True)
        st.markdown(
        """
        <div style='
            background-color: #EEEEEE;
            padding: 10px 20px;
            border-radius: 10px;
            border: 1px solid #ccc;
            margin-bottom: 30px;
            text-align: center;
        '>
            <h4 style='color: #1a1a1a;'> Simulate a product recommendation engine based on user interactions and product similarities.Now includes AI-driven dynamic pricing adjustments. </h4>
        """,
        unsafe_allow_html=True
                )

        # --- Simulated Product Catalog ---
        def get_image_url(category):
            category_map = {
                "Footwear": "shoes",
                "Fitness": "fitness",
                "Electronics": "technology",
                "Wearables": "wearable",
                "Health": "health",
                "Accessories": "accessory",
                "Outdoor": "outdoor",
                "Home": "home",
                "Furniture": "furniture"
            }
            tag = category_map.get(category, "product")
            return f"https://loremflickr.com/200/200/{tag}?lock={np.random.randint(1,1000)}"

        def load_product_catalog():
            data = {
                "ProductID": [f"P{i:03d}" for i in range(1, 21)],
                "ProductName": [
                    "Running Shoes", "Bluetooth Speaker", "Yoga Mat", "Noise Cancelling Headphones",
                    "Wireless Mouse", "Smart Watch", "Protein Powder", "Laptop Stand", "Hiking Backpack",
                    "Electric Toothbrush", "Water Bottle", "Desk Lamp", "Gaming Chair", "Treadmill Mat",
                    "Fitness Tracker", "Portable Charger", "Jump Rope", "Resistance Bands", "Smart Scale",
                    "Action Camera"
                ],
                "Category": [
                    "Footwear", "Electronics", "Fitness", "Electronics", "Electronics", "Wearables", "Health",
                    "Accessories", "Outdoor", "Health", "Fitness", "Home", "Furniture", "Fitness",
                    "Wearables", "Electronics", "Fitness", "Fitness", "Health", "Electronics"
                ],
                "Tags": [
                    "shoes running sport", "audio speaker bluetooth", "yoga fitness mat",
                    "headphones noise bluetooth", "mouse wireless pc", "watch smart fitness",
                    "protein supplement health", "laptop ergonomic stand", "hiking outdoor travel",
                    "toothbrush electric oral", "bottle water gym", "lamp desk light",
                    "gaming chair comfort", "mat treadmill fitness", "fitness tracker wearable",
                    "charger portable power", "jump rope cardio", "bands resistance workout",
                    "scale smart health", "camera action sport"
                ],
                "Price": np.random.randint(20, 200, 20),
                "Rating": np.round(np.random.uniform(3.0, 5.0, 20), 1),
                "ReviewCount": np.random.randint(20, 500, 20)
            }
            df = pd.DataFrame(data)
            df["ImageURL"] = df["Category"].apply(get_image_url)
            df["BuyURL"] = df["ProductID"].apply(lambda pid: f"https://example.com/buy/{pid}")
            return df

        products_df = load_product_catalog()

        # --- Dynamic Pricing Section ---
        st.markdown(
        """
        <div style='
            background-color: #EEEEEE;
            padding: 10px 20px;
            border-radius: 10px;
            border: 1px solid #ccc;
            margin-bottom: 30px;
            text-align: left;
        '>
            <h4 style='color: #1a1a1a;'> üí∏ Dynamic Pricing Simulator </h4>
        """,
        unsafe_allow_html=True
                )
        #st.header("üí∏ Dynamic Pricing Simulator")
        st.markdown("""
        Adjust pricing dynamically based on real-world factors like demand, stock, and customer type.
        """)

        product_selection = st.selectbox("Choose a product to simulate pricing:", products_df["ProductName"])
        selected_row = products_df[products_df["ProductName"] == product_selection].iloc[0]

        base_price = selected_row["Price"]
        st.write(f"**Base Price:** ${base_price}")

        col1, col2, col3 = st.columns(3)
        with col1:
            demand_level = st.radio("Demand Level", ["Low", "Medium", "High"], index=1)
        with col2:
            stock_level = st.slider("Stock Level (%)", 0, 100, 50)
        with col3:
            segment = st.selectbox("Customer Segment", ["Regular", "VIP", "First-time"])

        promo = st.checkbox("Apply Promotion (10% off)")

        # --- Simple Rule-based Pricing Logic ---
        adjustment = 0
        if demand_level == "High":
            adjustment += 0.15
        elif demand_level == "Low":
            adjustment -= 0.10

        if stock_level < 30:
            adjustment += 0.10
        elif stock_level > 80:
            adjustment -= 0.05

        if segment == "VIP":
            adjustment -= 0.10
        elif segment == "First-time":
            adjustment -= 0.05

        if promo:
            adjustment -= 0.10

        new_price = base_price * (1 + adjustment)
        new_price = max(1, round(new_price, 2))

        st.subheader("üí∞ Final Price Suggestion")
        st.metric(label="New AI-Adjusted Price", value=f"${new_price}", delta=f"{round((new_price - base_price), 2)}")

        st.markdown(f"""
        ##### üß† Why this price?
        - Demand: **{demand_level}**
        - Stock: **{stock_level}%**
        - Customer: **{segment}**
        - Promotion: **{'Yes' if promo else 'No'}**
        - Adjusted from base price of ${base_price} ‚Üí **${new_price}**
        """)

    def Visual_AI(self):
        st.markdown("---", unsafe_allow_html=True)
        st.markdown(
        """
        <div style='
            background-color: #EEEEEE;
            padding: 10px 20px;
            border-radius: 10px;
            border: 1px solid #ccc;
            margin-bottom: 30px;
            text-align: center;
        '>
            <h4 style='color: #1a1a1a;'> Simulated Virtual Try-Ons </h4>
        </div>
        """, unsafe_allow_html=True)

        st.markdown(
        """
        <div style='
            background-color: #EEEEEE;
            padding: 10px 20px;
            border-radius: 10px;
            border: 1px solid #ccc;
            margin-bottom: 30px;
            text-align: center;
        '>
            <h4 style='color: #1a1a1a;'> üßç‚Äç‚ôÇÔ∏è AI Virtual Try-On Simulator </h4>
        </div>
        """, unsafe_allow_html=True)

        uploaded_file = st.file_uploader("Upload your selfie (front-facing)", type=["jpg", "jpeg", "png"], key="Photo1")
        selected_items = st.multiselect("Try on: üëì üß¢ üëï", ["Glasses", "Hat", "T-Shirt"], key="Accesories1")

        overlay_paths = {
            "Glasses": "C:/Users/Prasad/Anaconda3/envs/py39/AI_Webinar/Real_World_Applications/Data/Retail/Virtual_Try_On/assets/glasses2-removebg-preview.png",
            "Hat": "C:/Users/Prasad/Anaconda3/envs/py39/AI_Webinar/Real_World_Applications/Data/Retail/Virtual_Try_On/assets/hat-.png",
            "T-Shirt": "C:/Users/Prasad/Anaconda3/envs/py39/AI_Webinar/Real_World_Applications/Data/Retail/Virtual_Try_On/assets/T-Shirt1-removebg-preview.png"
        }

        def load_overlay(path):
            try:
                return Image.open(path).convert("RGBA")
            except Exception as e:
                st.error(f"‚ùå Error loading overlay image: {e}")
                return None

        def detect_face_landmarks(image):
            with mp.solutions.face_mesh.FaceMesh(static_image_mode=True, max_num_faces=1, refine_landmarks=True) as face_mesh:
                img_np = np.array(image.convert("RGB"))
                results = face_mesh.process(img_np)
                if results.multi_face_landmarks:
                    return results.multi_face_landmarks[0].landmark
                return None

        def get_overlay_position(image, landmarks, item):
            w, h = image.size
            if item == "Glasses":
                left_eye = landmarks[33]
                right_eye = landmarks[263]
                lx, ly = int(left_eye.x * w), int(left_eye.y * h)
                rx, ry = int(right_eye.x * w), int(right_eye.y * h)
                width = abs(rx - lx)
                overlay_size = (width + 30, int(width * 0.4))
                position = (lx - 15, ly - 10)
            elif item == "Hat":
                forehead = landmarks[10]
                head_x = int(forehead.x * w)
                head_y = int(forehead.y * h)
                overlay_size = (int(w * 0.5), int(h * 0.25))
                x_offset = 12 
                y_offset = 13  # üëà Move hat 10 pixels higher (adjust as needed)
                position = (head_x - overlay_size[0] // 2, head_y - overlay_size[1] // 2 - y_offset)
            elif item == "T-Shirt":
                left_shoulder = landmarks[234]
                right_shoulder = landmarks[454]
                lx, ly = int(left_shoulder.x * w), int(left_shoulder.y * h)
                rx, ry = int(right_shoulder.x * w), int(right_shoulder.y * h)
                chest_width = abs(rx - lx)
                overlay_size = (chest_width * 2, chest_width * 2)
                y_offset = 80
                position = (lx - chest_width // 2, ly)
            else:
                overlay_size = (100, 100)
                position = (50, 50)
            return overlay_size, position

        def apply_overlay(image, overlay, position):
            image = image.convert("RGBA")
            overlay = overlay.convert("RGBA")
            image.paste(overlay, position, overlay)
            return image

        def apply_overlay_with_face(image, item):
            landmarks = detect_face_landmarks(image)
            if landmarks is None:
                st.warning("No face detected. Using fallback fixed placement.")
                return image

            overlay = load_overlay(overlay_paths[item])
            if overlay is None:
                return image

            size, pos = get_overlay_position(image, landmarks, item)
            overlay = overlay.resize((int(size[0]), int(size[1])))
            return apply_overlay(image, overlay, pos)

        if uploaded_file:
            image = Image.open(uploaded_file).convert("RGB")
            image = image.resize((320, 240))  # standard size for consistent landmark alignment
            st.image(image, caption="Original Image", use_container_width=True)

            result_img = image.copy()
            for item in selected_items:
                result_img = apply_overlay_with_face(result_img, item)

            st.image(result_img, caption="With Virtual Try-On", use_container_width=True)
            st.success("‚ú® Virtual try-on applied using face detection.")
        else:
            st.info("üì∏ Please upload a front-facing photo to try virtual items.")

        st.markdown("---")
        st.markdown(" ")
        st.markdown(
        """
        <div style='
            background-color: #EEEEEE;
            padding: 10px 20px;
            border-radius: 10px;
            border: 1px solid #ccc;
            margin-bottom: 30px;
            text-align: center;
        '>
            <h4 style='color: #1a1a1a;'> üßç‚Äç‚ôÇÔ∏è AI Virtual Try-On Simulator 2.0 </h4>
        </div>
        """, unsafe_allow_html=True)

        uploaded_file = st.file_uploader("Upload your selfie (front-facing)", type=["jpg", "jpeg", "png"], key="Photo2")

        # --- Accessory Options ---
        overlay_style_paths = {
            "Glasses": {
                "Classic": "C:/Users/Prasad/Anaconda3/envs/py39/AI_Webinar/Real_World_Applications/Data/Retail/Virtual_Try_On/assets/Aviator_SG-removebg-preview-removebg-preview.png",
                "Aviator": "C:/Users/Prasad/Anaconda3/envs/py39/AI_Webinar/Real_World_Applications/Data/Retail/Virtual_Try_On/assets/Aviator_SG-removebg-preview-removebg-preview.png",
                "Round": "C:/Users/Prasad/Anaconda3/envs/py39/AI_Webinar/Real_World_Applications/Data/Retail/Virtual_Try_On/assets/Aviator_SG-removebg-preview-removebg-preview.png"
            },
            "Hat": {
                "Fedora": "C:/Users/Prasad/Anaconda3/envs/py39/AI_Webinar/Real_World_Applications/Data/Retail/Virtual_Try_On/assets/Fedora_Hat-removebg-preview-removebg-preview.png",
                "Party": "C:/Users/Prasad/Anaconda3/envs/py39/AI_Webinar/Real_World_Applications/Data/Retail/Virtual_Try_On/assets/Fedora_Hat-removebg-preview-removebg-preview.png",
                "Cap": "C:/Users/Prasad/Anaconda3/envs/py39/AI_Webinar/Real_World_Applications/Data/Retail/Virtual_Try_On/assets/Fedora_Hat-removebg-preview-removebg-preview.png"
            }
        }

        # --- Load Overlay ---
        def load_overlay(path):
            try:
                return Image.open(path).convert("RGBA")
            except Exception as e:
                st.error(f"‚ùå Error loading overlay: {e}")
                return None

        # --- Face Landmark Detection ---
        def detect_face_landmarks(image):
            with mp.solutions.face_mesh.FaceMesh(static_image_mode=True, max_num_faces=1, refine_landmarks=True) as face_mesh:
                img_np = np.array(image.convert("RGB"))
                results = face_mesh.process(img_np)
                return results.multi_face_landmarks[0].landmark if results.multi_face_landmarks else None

        # --- Apply Overlay with Adjustments ---
        def apply_overlay(image, overlay, pos, scale=1.0):
            image = image.convert("RGBA")
            new_size = (int(overlay.width * scale), int(overlay.height * scale))
            overlay = overlay.resize(new_size)
            image.paste(overlay, pos, overlay)
            return image

        # --- Position Calculation ---
        def get_overlay_position(landmarks, w, h, item):
            if item == "Glasses":
                left_eye = landmarks[33]
                right_eye = landmarks[263]
                lx, ly = int(left_eye.x * w), int(left_eye.y * h)
                rx = int(right_eye.x * w)
                width = abs(rx - lx)
                return (lx - 15, ly - 10), width
            elif item == "Hat":
                top = landmarks[10]
                cx = int(top.x * w)
                cy = int(top.y * h)
                return (cx - 100, cy - 120), 200
            return (50, 50), 100

        if uploaded_file:
            image = Image.open(uploaded_file).convert("RGB").resize((640, 480))
            landmarks = detect_face_landmarks(image)
            result_img = image.copy().convert("RGBA")

            selected_items = st.multiselect("Try on: üëì üß¢ üëï", ["Glasses", "Hat", "T-Shirt"], key="Accesories2")

            for item in selected_items:
                st.markdown(f"### {item} Settings")
                style = st.selectbox(f"{item} Style", list(overlay_style_paths[item].keys()), key=f"{item}_style")
                x_offset = st.slider(f"{item} X Offset", -200, 200, 0, key=f"{item}_x")
                y_offset = st.slider(f"{item} Y Offset", -200, 200, 0, key=f"{item}_y")
                scale = st.slider(f"{item} Scale (%)", 50, 150, 100, key=f"{item}_scale")

                overlay_path = overlay_style_paths[item][style]
                overlay = load_overlay(overlay_path)

                if landmarks:
                    w, h = image.size
                    base_pos, base_width = get_overlay_position(landmarks, w, h, item)
                    new_pos = (base_pos[0] + x_offset, base_pos[1] + y_offset)
                    result_img = apply_overlay(result_img, overlay, new_pos, scale / 100)

            st.image(result_img, caption="üßç Result with Accessories", use_container_width=True)

            # üì§ Download button
            buf = BytesIO()
            result_img.save(buf, format="PNG")
            st.download_button("üì• Download Result", data=buf.getvalue(), file_name="tryon_result.png", mime="image/png")
        else:
            st.info("üì∏ Upload a front-facing selfie to begin.")

        # --- Optional: Apply Color Tint on an Overlay ---
        def apply_color_tint(overlay_img, hex_color):
            tint = Image.new("RGBA", overlay_img.size, hex_color + "80")  # 50% opacity
            return Image.alpha_composite(overlay_img, tint)

        # --- Webcam Frame Processor ---
        class VirtualTryOnTransformer(VideoTransformerBase):
            def __init__(self):
                self.accessory = "Glasses"
                self.style = "Classic"
                self.scale = 1.0
                self.x_offset = 0
                self.y_offset = 0
                self.tint_color = "#00ff00"

            def set_params(self, accessory, style, scale, x_offset, y_offset, tint_color):
                self.accessory = accessory
                self.style = style
                self.scale = scale
                self.x_offset = x_offset
                self.y_offset = y_offset
                self.tint_color = tint_color

            def transform(self, frame):
                img = frame.to_ndarray(format="rgb24")
                pil_img = Image.fromarray(img).resize((640, 480)).convert("RGBA")
                landmarks = detect_face_landmarks(pil_img)

                if not landmarks:
                    return img

                overlay = load_overlay(overlay_style_paths[self.accessory][self.style])
                overlay = apply_color_tint(overlay, self.tint_color.lstrip("#"))

                w, h = pil_img.size
                base_pos, _ = get_overlay_position(landmarks, w, h, self.accessory)
                pos = (base_pos[0] + self.x_offset, base_pos[1] + self.y_offset)

                pil_img = apply_overlay(pil_img, overlay, pos, self.scale)

                return np.array(pil_img)

        # --- Sidebar for Webcam Try-On ---
        st.sidebar.markdown("## üé• Webcam Try-On")

        if st.sidebar.checkbox("Activate Webcam Try-On"):
            accessory = st.sidebar.selectbox("Accessory", ["Glasses", "Hat"], key="webcam_acc")
            style = st.sidebar.selectbox("Style", list(overlay_style_paths[accessory].keys()), key="webcam_style")
            x_offset = st.sidebar.slider("X Offset", -200, 200, 0, key="webcam_x")
            y_offset = st.sidebar.slider("Y Offset", -200, 200, 0, key="webcam_y")
            scale = st.sidebar.slider("Scale (%)", 50, 150, 100, key="webcam_scale") / 100
            tint_color = st.sidebar.color_picker("Color Tint", "#00ff00", key="webcam_tint")

            webrtc_ctx = webrtc_streamer(
                key="virtual-tryon",
                video_processor_factory=lambda: VirtualTryOnTransformer(),
                async_processing=True
            )

            if webrtc_ctx.video_processor:
                webrtc_ctx.video_processor.set_params(accessory, style, scale, x_offset, y_offset, tint_color)
